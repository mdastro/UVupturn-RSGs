{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "../Results/fit_results_3d_grid.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-75c6e5f4eb00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_probability\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Results/fit_results_3d_grid.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Results/model_prob_3d_grid.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mlldantas/anaconda3/envs/py2k7/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mlldantas/anaconda3/envs/py2k7/lib/python2.7/site-packages/numpy/lib/_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mlldantas/anaconda3/envs/py2k7/lib/python2.7/site-packages/numpy/lib/_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    616\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: ../Results/fit_results_3d_grid.csv not found."
     ]
    }
   ],
   "source": [
    "new_probability  = np.loadtxt('../../../Codes/Results/fit_results_3d_grid.csv', delimiter=',', dtype=str)\n",
    "results          = np.loadtxt('../Results/model_prob_3d_grid.csv', delimiter=',', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_probability = {}\n",
    "for i in range(len(new_probability[0, :])):                             # Converting numpy array into dictionary\n",
    "    my_probability[new_probability[0, i]] = np.array(new_probability[0 + 1:, i], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = my_probability['parameter']\n",
    "for i in range(param.size):\n",
    "    print param[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print results[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_results = {}\n",
    "for i in range(len(results[0, :])):                             # Converting numpy array into dictionary\n",
    "    my_results[results[0, i]] = np.array(results[0 + 1:, i], dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_probability.shape\n",
    "print new_probability[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter    = my_probability['parameter'].astype(str)\n",
    "quartile_1st = my_probability['25%'].astype(float)\n",
    "quartile_3rd = my_probability['75%'].astype(float)\n",
    "quantile_25  = my_probability['2.5%'].astype(float)\n",
    "quantile_97  = my_probability['97.5%'].astype(float)\n",
    "mean         = my_probability['mean'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.unique(parameter).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability   = my_results['pnew'].astype(float)\n",
    "redshift      = my_results['redshift'].astype(float)\n",
    "stellar_mass  = my_results['stellar_mass'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mean.size\n",
    "print probability.size\n",
    "print redshift.size\n",
    "print stellar_mass.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_beg = []\n",
    "idx_end = []\n",
    "for i in range(parameter.size):\n",
    "    if (parameter[i]=='pnew[0]'):\n",
    "        idx_beg = int(i)\n",
    "        print idx_beg\n",
    "        print 'ok'\n",
    "    elif (parameter[i]=='pnew[2499]'):\n",
    "        idx_end = int(i)\n",
    "        print idx_end\n",
    "        print 'ok'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_q1 = quartile_1st[idx_beg:idx_end+1]\n",
    "new_q3 = quartile_3rd[idx_beg:idx_end+1]\n",
    "new_25 = quantile_25[idx_beg:idx_end+1]\n",
    "new_97 = quantile_97[idx_beg:idx_end+1]\n",
    "new_param = parameter[idx_beg:idx_end+1]\n",
    "new_mean = mean[idx_beg:idx_end+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_mean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print redshift.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# plt.scatter(redshift, sersic_gal, mean, c = '#feb24c', alpha=0.7)\n",
    "ax.plot_trisurf(redshift, stellar_mass, new_mean, color='#a6611a', alpha=0.8, linewidth=0, antialiased=False)\n",
    "ax.set_xlabel(\"\\n z\", fontsize=14)\n",
    "ax.set_ylabel(\"\\n Log M$_*$ (M$_\\odot$)\", fontsize=14)\n",
    "ax.set_zlabel(\"\\n Probability of \\n UV upturn\", fontsize=14)\n",
    "for t in ax.yaxis.get_major_ticks(): t.label.set_fontsize(10)\n",
    "ax.set_yticks([9.75, 10.25, 10.75, 11.25, 11.75])\n",
    "ax.view_init(elev=22., azim=315)\n",
    "# ax.zaxis.set_rotate_label(False)\n",
    "plt.savefig('./../../Figs/logit3D_grid.pdf', dpi=100)\n",
    "\n",
    "# for ii in xrange(180,360,10):\n",
    "#     ax.view_init(elev=10., azim=ii)\n",
    "#     plt.savefig(\"./Results/movie_short/movie_0%d_0.png\" % ii)\n",
    "    \n",
    "# plt.savefig(\"./movie_0%d.png\" % 359)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(redshift, new_mean, alpha=0.2)\n",
    "plt.xlabel(\"Redshift\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.savefig(\"./Results/dependency01.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(stellar_mass, new_mean, alpha=0.2)\n",
    "plt.xlabel(\"Stellar Mass\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.savefig(\"./Results/dependency02.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.unique(redshift).size\n",
    "print redshift.size\n",
    "print np.unique(redshift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find in which indices the redshifts are the same, so we can estimate medians (of prob., 1st quartile, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_redshifts = np.unique(redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idxs_unique = []\n",
    "matrix = []\n",
    "for i in range(unique_redshifts.size):\n",
    "    idxs_unique.append(\"z_%d\" % i)\n",
    "    idxs_unique.append(unique_redshifts[i])\n",
    "    for j in range(redshift.size):\n",
    "        if unique_redshifts[i] == redshift[j]:\n",
    "            idxs_unique.append(j)\n",
    "        else:\n",
    "            continue\n",
    "new_dataset =  np.array(idxs_unique).reshape(50,52).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mass = np.unique(stellar_mass)\n",
    "print unique_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_dataset[:,0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prob = []\n",
    "prob_i = []\n",
    "q1_i   = []\n",
    "q3_i   = []\n",
    "q97_i  = []\n",
    "q25_i  = []\n",
    "matrix = []\n",
    "\n",
    "for k in range(new_dataset[2:,0].size):\n",
    "    column   = new_dataset[:,k]\n",
    "    idxs_col = column[2:]\n",
    "    mean_prob = list(column[1:2])\n",
    "#     print mean_prob\n",
    "    for m in idxs_col:\n",
    "        prob_i.append(new_mean[int(m)])\n",
    "        q1_i.append(new_q1[int(m)])\n",
    "        q3_i.append(new_q3[int(m)])\n",
    "        q97_i.append(new_97[int(m)])\n",
    "        q25_i.append(new_25[int(m)])\n",
    "    prob = np.mean(np.array(prob_i))\n",
    "    q1   = np.mean(np.array(q1_i))\n",
    "    q3   = np.mean(np.array(q3_i))\n",
    "    q97  = np.mean(np.array(q97_i))\n",
    "    q25  = np.mean(np.array(q25_i))\n",
    "    mean_prob.append(prob)\n",
    "    mean_prob.append(q1)\n",
    "    mean_prob.append(q3)\n",
    "    mean_prob.append(q25)\n",
    "    mean_prob.append(q97)\n",
    "    matrix.append(mean_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do a similar thing for the mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beeing completely over cautious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_unique_m = []\n",
    "matrix_m = []\n",
    "for i in range(unique_mass.size):\n",
    "    idxs_unique_m.append(\"m_%d\" % i)\n",
    "    idxs_unique_m.append(unique_mass[i])\n",
    "    for j in range(stellar_mass.size):\n",
    "        if unique_mass[i] == stellar_mass[j]:\n",
    "            idxs_unique_m.append(j)\n",
    "        else:\n",
    "            continue\n",
    "new_dataset_m = np.array(idxs_unique_m).reshape(50,52).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_dataset_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prob_m = []\n",
    "prob_i_m = []\n",
    "q1_i_m   = []\n",
    "q3_i_m   = []\n",
    "q97_i_m  = []\n",
    "q25_i_m  = []\n",
    "matrix_m = []\n",
    "\n",
    "for k in range(new_dataset_m[2:,0].size):\n",
    "    column      = new_dataset_m[:,k]\n",
    "    idxs_col    = column[2:]\n",
    "    mean_prob_m = list(column[1:2])\n",
    "#     print mean_prob\n",
    "    for m in idxs_col:\n",
    "        prob_i_m.append(new_mean[int(m)])\n",
    "        q1_i_m.append(new_q1[int(m)])\n",
    "        q3_i_m.append(new_q3[int(m)])\n",
    "        q97_i_m.append(new_97[int(m)])\n",
    "        q25_i_m.append(new_25[int(m)])\n",
    "    prob = np.mean(np.array(prob_i_m))\n",
    "    q1   = np.mean(np.array(q1_i_m))\n",
    "    q3   = np.mean(np.array(q3_i_m))\n",
    "    q97  = np.mean(np.array(q97_i_m))\n",
    "    q25  = np.mean(np.array(q25_i_m))\n",
    "    mean_prob_m.append(prob)\n",
    "    mean_prob_m.append(q1)\n",
    "    mean_prob_m.append(q3)\n",
    "    mean_prob_m.append(q25)\n",
    "    mean_prob_m.append(q97)\n",
    "    matrix_m.append(mean_prob_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_m = np.array(matrix_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print matrix_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_dataset_m[1]\n",
    "print unique_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remodled_data_z = {}\n",
    "remodled_data_z['redshift']         = np.array(matrix).T[0]\n",
    "remodled_data_z['new_probability']  = np.array(matrix).T[1]\n",
    "remodled_data_z['new_1st_quartile'] = np.array(matrix).T[2]\n",
    "remodled_data_z['new_3rd_quartile'] = np.array(matrix).T[3]\n",
    "remodled_data_z['new_2.5_quantile'] = np.array(matrix).T[4]\n",
    "remodled_data_z['new_97_quantile']  = np.array(matrix).T[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remodled_data_m = {}\n",
    "remodled_data_m['mass']             = np.array(matrix_m).T[0]\n",
    "remodled_data_m['new_probability']  = np.array(matrix_m).T[1]\n",
    "remodled_data_m['new_1st_quartile'] = np.array(matrix_m).T[2]\n",
    "remodled_data_m['new_3rd_quartile'] = np.array(matrix_m).T[3]\n",
    "remodled_data_m['new_2.5_quantile'] = np.array(matrix_m).T[4]\n",
    "remodled_data_m['new_97_quantile']  = np.array(matrix_m).T[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x   = remodled_data_z['redshift'].astype('float')\n",
    "y0  = remodled_data_z['new_1st_quartile'].astype('float')\n",
    "y1  = remodled_data_z['new_probability'].astype('float')\n",
    "y2  = remodled_data_z['new_3rd_quartile'].astype('float')\n",
    "y25 = remodled_data_z['new_2.5_quantile'].astype('float')\n",
    "y97 = remodled_data_z['new_97_quantile'] .astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#1b9e77','#d95f02','#7570b3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.\n",
    "\n",
    "plt.subplots(1,1, figsize=(8,5.1))\n",
    "plot25, = plt.plot(x, y25, '-.', color=palette[1], label=\"2.5%\")\n",
    "plotq1, = plt.plot(x, y0,  ':',  color=palette[1], label=\"25%\")\n",
    "plotq2, = plt.plot(x, y1,  '-',  color=palette[2], label='Median')\n",
    "plotq3, = plt.plot(x, y2,  ':',  color=palette[1], label=\"75%\")\n",
    "plot97, = plt.plot(x, y97, '-.', color=palette[1], label=\"97.5%\")\n",
    "\n",
    "# l1 = plt.legend([plot25, plotq1], [\"2.5%\", \"1$^{\\mathrm{st}}$ quartile (25%)\"], \n",
    "#                 numpoints=1, loc='lower center', fontsize=12, frameon=True, framealpha=0.85)\n",
    "# l2 = plt.legend([plotq2, plotq3, plot97], [\"Median\", \"3$^{\\mathrm{rd}}$ quartile (75%)\", \"97.5%\"], numpoints=1, \n",
    "#                 loc='lower right', fontsize=12, frameon=True, framealpha=0.85)\n",
    "# l1.get_frame().set_edgecolor('black')\n",
    "# l2.get_frame().set_edgecolor('black')\n",
    "# plt.gca().add_artist(l1)\n",
    "plt.fill_between(x, y0, y2,   facecolor=palette[0], alpha=0.1) # credible intervals\n",
    "plt.fill_between(x, y25, y97, facecolor=palette[0], alpha=0.1) # credible intervals\n",
    "plt.ylim([0,0.7])\n",
    "plt.xlabel(\"Redshift\", fontsize=15)\n",
    "plt.ylabel(\"Probability of UV upturn\", fontsize=15)\n",
    "plt.legend(numpoints=1, loc='lower right', fontsize=12, frameon=True, framealpha=1.)\n",
    "plt.tick_params('both', labelsize='14')\n",
    "plt.savefig('./Results/prob_z.png')\n",
    "plt.savefig('./Results/prob_z.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z    = remodled_data_m['mass'].astype('float')\n",
    "y0m  = remodled_data_m['new_1st_quartile'].astype('float')\n",
    "y1m  = remodled_data_m['new_probability'].astype('float')\n",
    "y2m  = remodled_data_m['new_3rd_quartile'].astype('float')\n",
    "y25m = remodled_data_m['new_2.5_quantile'].astype('float')\n",
    "y97m = remodled_data_m['new_97_quantile'] .astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.\n",
    "\n",
    "plt.subplots(1,1, figsize=(8,5.1))\n",
    "plot25, = plt.plot(z, y25m, '-.', color=palette[1], label=\"2.5%\")\n",
    "plotq1, = plt.plot(z, y0m,  ':',  color=palette[1], label=\"25%\")\n",
    "plotq2, = plt.plot(z, y1m,  '-',  color=palette[2], label='Median')\n",
    "plotq3, = plt.plot(z, y2m,  ':',  color=palette[1], label=\"75%\")\n",
    "plot97, = plt.plot(z, y97m, '-.', color=palette[1], label=\"97.5%\")\n",
    "plt.fill_between(z, y0m, y2m,   facecolor=palette[0], alpha=0.1) # credible intervals\n",
    "plt.fill_between(z, y25m, y97m, facecolor=palette[0], alpha=0.1) # credible intervals\n",
    "plt.xlabel(\"$\\log$ M$_*$ (M$_\\odot$)\", fontsize=15)\n",
    "plt.ylabel(\"Probability of UV upturn\", fontsize=15)\n",
    "plt.legend(numpoints=1, loc='lower right', fontsize=12, frameon=True, framealpha=1)\n",
    "plt.tick_params('both', labelsize='14')\n",
    "plt.ylim([0., 0.7])\n",
    "plt.savefig('./Results/prob_mass.png')\n",
    "plt.savefig('./Results/prob_mass.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = unique_mass\n",
    "x2 = unique_redshifts\n",
    "plt.plot(x, z, 'o', alpha=0.8)\n",
    "plt.xlabel(\"Redshift\")\n",
    "plt.ylabel(\"Mass\")\n",
    "plt.savefig('./Results/mass_z.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
