{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal functions to be called throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(parameter):\n",
    "    \"\"\"\n",
    "    :param parameter: the array with the parameters you wish to standardize\n",
    "    :return param_mean: mean of the input array\n",
    "    :return param_std : standard deviation of the input array\n",
    "    :return stdized_param: final standardized array\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    param_mean    = np.mean(parameter)\n",
    "    param_std     = np.std(parameter)\n",
    "    stdized_param = []                  # standardized parameter -- output\n",
    "    for i in range(parameter.size):\n",
    "        param_temp = (parameter[i] - param_mean)/param_std\n",
    "        stdized_param.append(param_temp)\n",
    "    stdized_param = np.array(stdized_param)\n",
    "    return (param_mean, param_std, stdized_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_standardize(stdized_par, mean, std):\n",
    "    \"\"\"\n",
    "    This function undoes what the former does!\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    recovered_par = []\n",
    "    for i in range(stdized_par.size):\n",
    "        param_temp = stdized_par[i]*std + mean\n",
    "        recovered_par.append(param_temp)\n",
    "    recovered_par = np.array(recovered_par)\n",
    "    return (recovered_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_plots(x, row, col, position):\n",
    "#     import numpy             as np\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn           as sns\n",
    "    \n",
    "# #     plot_dict = {}\n",
    "# #     plot_dict[\"plot{0}{1}\".format(row, col)] \n",
    "#     fig = plt.subplot(row+1, col+1, position)\n",
    "#     sns.kdeplot(x, shade=True, c='#e6550d')\n",
    "#     plt.xlabel(r\"$\\beta_{%d%d}$\" % (row, col), fontsize=12)\n",
    "#     plt.tick_params('both', labelsize='12')\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return (fig)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api   as sm\n",
    "import seaborn           as sns\n",
    "import pystan\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../../Catalogue/binom_reg_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the dataset\n",
    "redshifts = my_data['Z']\n",
    "index     = np.where(redshifts.values<=0.4)\n",
    "\n",
    "# parameters of interest\n",
    "logit_class = my_data['LOGIT_CLASS(1-UVUP;0-UVWEAK)'].values[index]    # y axis: logit class -- uv upturn yes or no\n",
    "whan_class  = my_data['WHAN(0-NA;1-RP;2-wA;3-sA;4-SF)'].values[index]  # My types of galaxies\n",
    "mass        = my_data['STELLAR_MASS'].values[index]                    # 1st parameter\n",
    "redshift    = redshifts.values[index]                                  # 2nd parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original parameters\n",
    "mean_mass, std_mass, x2 = standardize(mass)\n",
    "x1      = redshift\n",
    "y       = logit_class\n",
    "classes = (whan_class+1).astype(int)        # Must sum +1 to avoid index issues with STAN\n",
    "n_obs   = x1.size\n",
    "n_class = np.unique(classes).size\n",
    "\n",
    "# new parameters - important for plotting!\n",
    "n_obs2 = 30\n",
    "x1_sim = np.linspace(x1.min(), x1.max(), n_obs2)\n",
    "x2_sim = np.linspace(x2.min(), x2.max(), n_obs2)\n",
    "\n",
    "# grid\n",
    "plot_x1, plot_x2 = np.meshgrid(x1_sim, x2_sim)  # THIS IS WHERE THE GRID IS DONE\n",
    "plot_x1 = plot_x1.reshape((n_obs2**2), 1)\n",
    "plot_x2 = plot_x2.reshape((n_obs2**2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0048533107143856 2.6904846038511474\n",
      "0.018866401595684694\n",
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "print x2.min(), x2.max() # sanity check\n",
    "print np.median(x2)\n",
    "print plot_x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to be used in the regression\n",
    "regression_data      = {}                                                 # Dictionary, as stated in the pystan manual\n",
    "regression_data['Y'] = y\n",
    "regression_data['X'] = sm.add_constant(np.column_stack((x1, x1**2, x2, x2**2)))\n",
    "regression_data['K'] = regression_data['X'][0,:].size                     # Number of betas -- b0, b1, b2, b3, b4\n",
    "regression_data['W'] = classes\n",
    "regression_data['N'] = n_obs\n",
    "regression_data['C'] = n_class                                      # Number of different classes (partial pooling)\n",
    "\n",
    "# dataset to be used in the plot -- after meshgrid\n",
    "regression_data['X2'] = sm.add_constant(np.column_stack((plot_x1, plot_x1**2, plot_x2, plot_x2)))\n",
    "regression_data['N2'] = n_obs2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 5)\n"
     ]
    }
   ],
   "source": [
    "print regression_data['X2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit: STAN code ----------------------------------------------------------------------------------------------------------\n",
    "stan_code = \"\"\"\n",
    "// DECLARATION OF VARIABLES -----------------------------------------------------------------------------------------------\n",
    "data{\n",
    "    int<lower=1> N;\n",
    "    int<lower=1> N2;\n",
    "    int<lower=1> K;\n",
    "    int<lower=1> C;\n",
    "    int W[N];\n",
    "    int<lower=0, upper=1> Y[N];\n",
    "    matrix[N, K] X;         // redshift and stellar mass \n",
    "    matrix[N2,K] X2;        // redshift and stellar mass -- after grid\n",
    "    }\n",
    "\n",
    "// DEFINING THE PRIOR(S) --------------------------------------------------------------------------------------------------\n",
    "parameters{\n",
    "    matrix[K,C] beta;       // 25 betas!\n",
    "    real<lower=0> sigma;    // Shared hyperpriors\n",
    "    real mu;                // Shared hyperpriors\n",
    "    }\n",
    "\n",
    "// MODEL: PROBABILITY, HYPERPRIORS, PRIORS, AND REGRESSION ----------------------------------------------------------------\n",
    "model {\n",
    "   vector[N] prob;\n",
    "    for (i in 1:N) {\n",
    "      prob[i] = beta[1,W[i]]*X[i,1] + beta[2,W[i]]*X[i,2] + beta[3,W[i]]*X[i,3] + beta[4,W[i]]*X[i,4] + \n",
    "      beta[5,W[i]]*X[i,5];\n",
    "      }\n",
    "\n",
    "    sigma ~ gamma(0.001, 0.001);                           // shared hyperpriors\n",
    "    mu ~ normal(0, 100);                                   // shared hyperpriors\n",
    "     \n",
    "    for (i in 1:K) {\n",
    "       for (j in 1:C) beta[i,j] ~ normal(mu, sigma);       // priors\n",
    "        }\n",
    "\n",
    "    Y ~ bernoulli_logit(prob);                             // regression\n",
    "    }\n",
    "\n",
    "// DATA TO BE PLOTTED -----------------------------------------------------------------------------------------------------\n",
    "generated quantities{\n",
    "    vector[N2] prob01;\n",
    "    vector[N2] eta01;\n",
    "    vector[N2] prob02;\n",
    "    vector[N2] eta02;\n",
    "    vector[N2] prob03;\n",
    "    vector[N2] eta03;\n",
    "    vector[N2] prob04;\n",
    "    vector[N2] eta04;\n",
    "    vector[N2] prob05;\n",
    "    vector[N2] eta05;\n",
    "    \n",
    "    for(j in 1:N2){\n",
    "        eta01[j] = beta[1,1]*X2[j,1] + beta[2,1]*X2[j,2] + beta[3,1]*X2[j,3] + beta[4,1]*X2[j,4] + beta[5,1]*X2[j,5];\n",
    "        eta02[j] = beta[1,2]*X2[j,1] + beta[2,2]*X2[j,2] + beta[3,2]*X2[j,3] + beta[4,2]*X2[j,4] + beta[5,2]*X2[j,5];\n",
    "        eta03[j] = beta[1,3]*X2[j,1] + beta[2,3]*X2[j,2] + beta[3,3]*X2[j,3] + beta[4,3]*X2[j,4] + beta[5,3]*X2[j,5];\n",
    "        eta04[j] = beta[1,4]*X2[j,1] + beta[2,4]*X2[j,2] + beta[3,4]*X2[j,3] + beta[4,4]*X2[j,4] + beta[5,4]*X2[j,5];\n",
    "        eta05[j] = beta[1,5]*X2[j,1] + beta[2,5]*X2[j,2] + beta[3,5]*X2[j,3] + beta[4,5]*X2[j,4] + beta[5,5]*X2[j,5];\n",
    "        prob01[j] = inv_logit(eta01[j]);\n",
    "        prob02[j] = inv_logit(eta02[j]);\n",
    "        prob03[j] = inv_logit(eta03[j]);\n",
    "        prob04[j] = inv_logit(eta04[j]);\n",
    "        prob05[j] = inv_logit(eta05[j]);\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for running STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations    = 8000\n",
    "chains        = 2                           # HMC chains\n",
    "warmup        = 2000                        # How many of the first iterations we'll ignore - burnin\n",
    "jobs          = -1                          # Run code in parallel -- see pystan documentation\n",
    "seed          = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = {}\n",
    "# control['max_treedepth'] = 20\n",
    "control['adapt_delta'] = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_902d543734551fafeca59854d8a03fd0 NOW.\n",
      "/home/mlldantas/anaconda3/envs/py2k7/lib/python2.7/site-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/tmpW5eYgE/stanfit4anon_model_902d543734551fafeca59854d8a03fd0_7675752649170245185.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "WARNING:pystan:5 of 12000 iterations ended with a divergence (0%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.85 to remove the divergences.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "fit = pystan.stan(model_code=stan_code, data=regression_data, seed=seed, iter=iterations, chains=chains, \n",
    "                  warmup=warmup, n_jobs=jobs, control=control)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "CPU process time: 9.41 [min]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting fit properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pystan.stansummary(fit=fit, digits_summary=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_arr = np.array(summary.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = summary_arr[5:-6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_output[15] = 'beta[1,4]    -0.15   0.002   0.24  -0.65 -0.294 -0.137-4.17e-4  0.312  13106    1.0' \n",
      "new_output[4549] = 'eta03[23]   -0.042    0.01  1.041 -2.187 -0.6532.45e-4  0.602  1.946   9954    1.0' \n",
      "new_output[4550] = 'eta03[24]   -0.043    0.01  1.041  -2.19 -0.6543.95e-4  0.602  1.945   9962    1.0' \n",
      "new_output[4551] = 'eta03[25]   -0.044    0.01  1.041 -2.191 -0.653-5.31e-4    0.6  1.943   9970    1.0' \n",
      "new_output[4554] = 'eta03[28]   -0.046    0.01  1.041 -2.193 -0.656-3.58e-5  0.598   1.94   9996    1.0' \n",
      "new_output[4566] = 'eta03[40]   -0.038    0.01  0.979 -2.067 -0.6118.07e-4  0.572  1.826   9852    1.0' \n",
      "new_output[4568] = 'eta03[42]   -0.039    0.01  0.979 -2.068 -0.6127.95e-4   0.57  1.824   9867    1.0' \n",
      "new_output[4569] = 'eta03[43]    -0.04    0.01  0.979 -2.067 -0.6122.41e-4  0.569  1.823   9874    1.0' \n",
      "new_output[4570] = 'eta03[44]    -0.04    0.01  0.979 -2.067 -0.612-1.0e-4  0.568  1.821   9882    1.0' \n",
      "new_output[4576] = 'eta03[50]   -0.044    0.01  0.979 -2.062 -0.619-9.06e-4  0.563  1.825   9930    1.0' \n",
      "new_output[4577] = 'eta03[51]   -0.045    0.01  0.979 -2.063 -0.619-8.97e-4  0.562  1.824   9939    1.0' \n",
      "new_output[4588] = 'eta03[62]   -0.038   0.009  0.918 -1.942 -0.574-1.1e-4  0.535  1.707   9789    1.0' \n",
      "new_output[4589] = 'eta03[63]   -0.038   0.009  0.918 -1.941 -0.574-8.22e-5  0.534  1.704   9797    1.0' \n",
      "new_output[4590] = 'eta03[64]   -0.039   0.009  0.918  -1.94 -0.574-8.14e-4  0.534  1.702   9804    1.0' \n",
      "new_output[6654] = 'eta04[328]  -0.011   0.004  0.447  -0.95 -0.271-1.5e-4  0.255   0.89  12833    1.0' \n",
      "new_output[6655] = 'eta04[329]  -0.011   0.004  0.448 -0.952 -0.272-8.37e-4  0.253   0.89  12850    1.0' \n",
      "new_output[6797] = 'eta04[471]   -0.16   0.002  0.255 -0.705 -0.314 -0.1475.21e-4  0.331  12442    1.0' \n",
      "new_output[6799] = 'eta04[473]  -0.162   0.002  0.257 -0.706 -0.316 -0.1492.68e-4  0.332  12381    1.0' \n",
      "new_output[6800] = 'eta04[474]  -0.162   0.002  0.258  -0.71 -0.318 -0.1491.43e-4  0.332  12351    1.0' \n",
      "new_output[6801] = 'eta04[475]  -0.163   0.002  0.259 -0.715 -0.319  -0.15-8.54e-6  0.333  12320    1.0' \n",
      "new_output[6802] = 'eta04[476]  -0.164   0.002   0.26 -0.719  -0.32 -0.1512.92e-4  0.336  12291    1.0' \n",
      "new_output[6803] = 'eta04[477]  -0.165   0.002  0.261 -0.723 -0.322 -0.1524.04e-4  0.336  12261    1.0' \n",
      "new_output[6804] = 'eta04[478]  -0.166   0.002  0.263 -0.726 -0.323 -0.1522.75e-4  0.338  12231    1.0' \n",
      "new_output[6805] = 'eta04[479]  -0.167   0.002  0.264 -0.729 -0.325 -0.154-4.16e-4  0.339  12202    1.0' \n",
      "new_output[6806] = 'eta04[480]  -0.168   0.002  0.265 -0.735 -0.327 -0.154-8.02e-4   0.34  12173    1.0' \n",
      "new_output[8638] = 'eta05[512]    -0.1   0.001  0.153  -0.41 -0.199 -0.0978.04e-4  0.194  13136    1.0' \n",
      "new_output[8639] = 'eta05[513]  -0.101   0.001  0.153  -0.41   -0.2 -0.0987.67e-4  0.194  13131    1.0' \n",
      "new_output[8640] = 'eta05[514]  -0.101   0.001  0.152 -0.411 -0.201 -0.0981.66e-4  0.193  13125    1.0' \n",
      "new_output[8641] = 'eta05[515]  -0.102   0.001  0.152 -0.411 -0.201 -0.099-6.62e-4  0.193  13120    1.0' \n",
      "29\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# for i in range(new_output.size):\n",
    "#     row = np.array(new_output[i].split())\n",
    "#     if row.size ==11:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print \"new_output[%d] = '%s' \" % (i, str(new_output[i]))\n",
    "#         count+=1\n",
    "# print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output[15] = 'beta[1,4]    -0.15   0.002   0.24  -0.65 -0.294 -0.137 -4.17e-4  0.312  13106    1.0' \n",
    "# new_output[4549] = 'eta03[23]   -0.042    0.01  1.041 -2.187 -0.653 2.45e-4  0.602  1.946   9954    1.0' \n",
    "# new_output[4550] = 'eta03[24]   -0.043    0.01  1.041  -2.19 -0.654 3.95e-4  0.602  1.945   9962    1.0' \n",
    "# new_output[4551] = 'eta03[25]   -0.044    0.01  1.041 -2.191 -0.653 -5.31e-4    0.6  1.943   9970    1.0' \n",
    "# new_output[4554] = 'eta03[28]   -0.046    0.01  1.041 -2.193 -0.656 -3.58e-5  0.598   1.94   9996    1.0' \n",
    "# new_output[4566] = 'eta03[40]   -0.038    0.01  0.979 -2.067 -0.611 8.07e-4  0.572  1.826   9852    1.0' \n",
    "# new_output[4568] = 'eta03[42]   -0.039    0.01  0.979 -2.068 -0.612 7.95e-4   0.57  1.824   9867    1.0' \n",
    "# new_output[4569] = 'eta03[43]    -0.04    0.01  0.979 -2.067 -0.612 2.41e-4  0.569  1.823   9874    1.0' \n",
    "# new_output[4570] = 'eta03[44]    -0.04    0.01  0.979 -2.067 -0.612 -1.0e-4  0.568  1.821   9882    1.0' \n",
    "# new_output[4576] = 'eta03[50]   -0.044    0.01  0.979 -2.062 -0.619 -9.06e-4  0.563  1.825   9930    1.0' \n",
    "# new_output[4577] = 'eta03[51]   -0.045    0.01  0.979 -2.063 -0.619 -8.97e-4  0.562  1.824   9939    1.0' \n",
    "# new_output[4588] = 'eta03[62]   -0.038   0.009  0.918 -1.942 -0.574 -1.1e-4  0.535  1.707   9789    1.0' \n",
    "# new_output[4589] = 'eta03[63]   -0.038   0.009  0.918 -1.941 -0.574 -8.22e-5  0.534  1.704   9797    1.0' \n",
    "# new_output[4590] = 'eta03[64]   -0.039   0.009  0.918  -1.94 -0.574 -8.14e-4  0.534  1.702   9804    1.0' \n",
    "# new_output[6654] = 'eta04[328]  -0.011   0.004  0.447  -0.95 -0.271 -1.5e-4  0.255   0.89  12833    1.0' \n",
    "# new_output[6655] = 'eta04[329]  -0.011   0.004  0.448 -0.952 -0.272 -8.37e-4  0.253   0.89  12850    1.0' \n",
    "# new_output[6797] = 'eta04[471]   -0.16   0.002  0.255 -0.705 -0.314 -0.147 5.21e-4  0.331  12442    1.0' \n",
    "# new_output[6799] = 'eta04[473]  -0.162   0.002  0.257 -0.706 -0.316 -0.149 2.68e-4  0.332  12381    1.0' \n",
    "# new_output[6800] = 'eta04[474]  -0.162   0.002  0.258  -0.71 -0.318 -0.149 1.43e-4  0.332  12351    1.0' \n",
    "# new_output[6801] = 'eta04[475]  -0.163   0.002  0.259 -0.715 -0.319  -0.15 -8.54e-6  0.333  12320    1.0' \n",
    "# new_output[6802] = 'eta04[476]  -0.164   0.002   0.26 -0.719  -0.32 -0.151 2.92e-4  0.336  12291    1.0' \n",
    "# new_output[6803] = 'eta04[477]  -0.165   0.002  0.261 -0.723 -0.322 -0.152 4.04e-4  0.336  12261    1.0' \n",
    "# new_output[6804] = 'eta04[478]  -0.166   0.002  0.263 -0.726 -0.323 -0.152 2.75e-4  0.338  12231    1.0' \n",
    "# new_output[6805] = 'eta04[479]  -0.167   0.002  0.264 -0.729 -0.325 -0.154 -4.16e-4  0.339  12202    1.0' \n",
    "# new_output[6806] = 'eta04[480]  -0.168   0.002  0.265 -0.735 -0.327 -0.154 -8.02e-4   0.34  12173    1.0' \n",
    "# new_output[8638] = 'eta05[512]    -0.1   0.001  0.153  -0.41 -0.199 -0.097 8.04e-4  0.194  13136    1.0' \n",
    "# new_output[8639] = 'eta05[513]  -0.101   0.001  0.153  -0.41   -0.2 -0.098 7.67e-4  0.194  13131    1.0' \n",
    "# new_output[8640] = 'eta05[514]  -0.101   0.001  0.152 -0.411 -0.201 -0.098 1.66e-4  0.193  13125    1.0' \n",
    "# new_output[8641] = 'eta05[515]  -0.102   0.001  0.152 -0.411 -0.201 -0.099 -6.62e-4  0.193  13120    1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(new_output.size):\n",
    "    row = np.array(new_output[i].split())\n",
    "    if row.size ==11:\n",
    "        continue\n",
    "    else:\n",
    "        print \"new_output[%d] = '%s' \" % (i, str(new_output[i]))\n",
    "        count+=1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'mean', u'se_mean', u'sd', u'2.5%', u'25%', u'50%', u'75%', u'97.5%', u'n_eff', u'Rhat']\n"
     ]
    }
   ],
   "source": [
    "header_fit = summary_arr[4].split()\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parameter', u'mean', u'se_mean', u'sd', u'2.5%', u'25%', u'50%', u'75%', u'97.5%', u'n_eff', u'Rhat']\n"
     ]
    }
   ],
   "source": [
    "header_addendum = 'parameter'\n",
    "header_fit = [header_addendum] + header_fit\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cute_output = list(np.zeros(len(header_fit)))\n",
    "for i in range(new_output.size):\n",
    "    if len(new_output[i].split())!=11: # the length of the list must be 11, in which case we connect them directly\n",
    "        print \"there is a problem!\"\n",
    "    else:\n",
    "        new_output_temp = np.array(new_output[i].split()).reshape(1,11)\n",
    "        cute_output     = np.vstack((cute_output, new_output_temp))\n",
    "cute_output = cute_output[1:,:]               # removing the zeroes in the beggining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and saving *ONLY* what really matters for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_mass  = un_standardize(stdized_par=plot_x2, mean=mean_mass, std=std_mass)\n",
    "regression_pars = np.column_stack((plot_x1, recovered_mass))\n",
    "rp              = regression_pars\n",
    "rp_cols         = np.vstack((rp, rp, rp, rp, rp))       # for 5 whan classes we must stack these 5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print np.unique(plot_x2).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 11)\n",
      "(4500, 2)\n"
     ]
    }
   ],
   "source": [
    "parameters = cute_output[:,0].astype(str)\n",
    "pnew_idxs  = []\n",
    "for i in range(parameters.size):\n",
    "    if parameters[i][0:4]=='prob':\n",
    "        pnew_idxs.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "model_results    = np.column_stack((cute_output[pnew_idxs,:], rp_cols))\n",
    "model_results_df = pd.DataFrame(model_results)\n",
    "model_results_df.columns = header_fit + ['Z'] + ['LOG_STELLAR_MASS']\n",
    "model_results_df.to_csv('./Results/fit_results_sharedprior.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prob01[31]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.664</td>\n",
       "      <td>3638</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prob01[32]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3642</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.07760758620689655</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prob01[33]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3646</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.0872751724137931</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prob01[34]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3650</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.09694275862068966</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prob01[35]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3654</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1066103448275862</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prob01[36]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3658</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.11627793103448275</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prob01[37]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3663</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1259455172413793</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prob01[38]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3667</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.13561310344827587</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prob01[39]</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3672</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1452806896551724</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prob01[40]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3676</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.15494827586206894</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prob01[41]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3681</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1646158620689655</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prob01[42]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3686</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.17428344827586206</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>prob01[43]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.663</td>\n",
       "      <td>3691</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.18395103448275862</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>prob01[44]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3696</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.19361862068965516</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>prob01[45]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.662</td>\n",
       "      <td>3701</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.20328620689655172</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>prob01[46]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3707</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.21295379310344825</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prob01[47]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3712</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.2226213793103448</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>prob01[48]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3718</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.23228896551724137</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>prob01[49]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3724</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.2419565517241379</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>prob01[50]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3729</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.25162413793103444</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>prob01[51]</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3735</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.261291724137931</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>prob01[52]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.661</td>\n",
       "      <td>3742</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.27095931034482756</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>prob01[53]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3749</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.2806268965517241</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prob01[54]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3756</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.2902944827586207</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>prob01[55]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3763</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.29996206896551725</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>prob01[56]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3770</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.3096296551724138</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prob01[57]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3778</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.3192972413793103</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>prob01[58]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3785</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.3289648275862069</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>prob01[59]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3793</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.33863241379310344</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>prob01[60]</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3801</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>9.796691931034484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>prob01[61]</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.651</td>\n",
       "      <td>3613</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>prob01[62]</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.651</td>\n",
       "      <td>3617</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.07760758620689655</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>prob01[63]</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3621</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.0872751724137931</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>prob01[64]</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3625</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.09694275862068966</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>prob01[65]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3630</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1066103448275862</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>prob01[66]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3634</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.11627793103448275</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>prob01[67]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3639</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1259455172413793</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>prob01[68]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3643</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.13561310344827587</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>prob01[69]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3648</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.1452806896551724</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>prob01[70]</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.649</td>\n",
       "      <td>3653</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.15494827586206894</td>\n",
       "      <td>9.863901862068966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8     9   \\\n",
       "0   prob01[31]   0.35  0.003  0.158  0.078  0.225  0.344  0.467  0.664  3638   \n",
       "1   prob01[32]   0.35  0.003  0.158  0.078  0.225  0.344  0.467  0.663  3642   \n",
       "2   prob01[33]   0.35  0.003  0.158  0.078  0.225  0.343  0.467  0.663  3646   \n",
       "3   prob01[34]   0.35  0.003  0.158  0.078  0.225  0.343  0.466  0.663  3650   \n",
       "4   prob01[35]   0.35  0.003  0.158  0.078  0.225  0.343  0.466  0.663  3654   \n",
       "5   prob01[36]   0.35  0.003  0.158  0.078  0.225  0.343  0.466  0.662  3658   \n",
       "6   prob01[37]   0.35  0.003  0.158  0.078  0.225  0.343  0.466  0.662  3663   \n",
       "7   prob01[38]   0.35  0.003  0.158  0.078  0.224  0.343  0.466  0.662  3667   \n",
       "8   prob01[39]   0.35  0.003  0.158  0.078  0.224  0.343  0.466  0.662  3672   \n",
       "9   prob01[40]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.663  3676   \n",
       "10  prob01[41]  0.349  0.003  0.158  0.078  0.224  0.343  0.465  0.663  3681   \n",
       "11  prob01[42]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.663  3686   \n",
       "12  prob01[43]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.663  3691   \n",
       "13  prob01[44]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.662  3696   \n",
       "14  prob01[45]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.662  3701   \n",
       "15  prob01[46]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.661  3707   \n",
       "16  prob01[47]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.661  3712   \n",
       "17  prob01[48]  0.349  0.003  0.158  0.078  0.224  0.343  0.466  0.661  3718   \n",
       "18  prob01[49]  0.349  0.003  0.158  0.077  0.224  0.342  0.466  0.661  3724   \n",
       "19  prob01[50]  0.349  0.003  0.158  0.077  0.224  0.342  0.466  0.661  3729   \n",
       "20  prob01[51]  0.349  0.003  0.158  0.077  0.224  0.342  0.465  0.661  3735   \n",
       "21  prob01[52]  0.348  0.003  0.158  0.077  0.224  0.342  0.465  0.661  3742   \n",
       "22  prob01[53]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3749   \n",
       "23  prob01[54]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3756   \n",
       "24  prob01[55]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3763   \n",
       "25  prob01[56]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3770   \n",
       "26  prob01[57]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3778   \n",
       "27  prob01[58]  0.348  0.003  0.158  0.077  0.224  0.342  0.464   0.66  3785   \n",
       "28  prob01[59]  0.348  0.003  0.158  0.077  0.224  0.342  0.465   0.66  3793   \n",
       "29  prob01[60]  0.348  0.003  0.158  0.077  0.224  0.342  0.464   0.66  3801   \n",
       "30  prob01[61]  0.354  0.003  0.152  0.088  0.235  0.349  0.466  0.651  3613   \n",
       "31  prob01[62]  0.354  0.003  0.152  0.088  0.235  0.349  0.466  0.651  3617   \n",
       "32  prob01[63]  0.354  0.003  0.152  0.088  0.235  0.349  0.465   0.65  3621   \n",
       "33  prob01[64]  0.354  0.003  0.152  0.088  0.235  0.349  0.465   0.65  3625   \n",
       "34  prob01[65]  0.353  0.003  0.152  0.088  0.235  0.349  0.465   0.65  3630   \n",
       "35  prob01[66]  0.353  0.003  0.152  0.088  0.235  0.349  0.465   0.65  3634   \n",
       "36  prob01[67]  0.353  0.003  0.152  0.088  0.235  0.349  0.465   0.65  3639   \n",
       "37  prob01[68]  0.353  0.003  0.151  0.088  0.235  0.349  0.465   0.65  3643   \n",
       "38  prob01[69]  0.353  0.003  0.151  0.088  0.235  0.349  0.465   0.65  3648   \n",
       "39  prob01[70]  0.353  0.003  0.151  0.088  0.235  0.349  0.464  0.649  3653   \n",
       "\n",
       "       10                   11                 12  \n",
       "0   1.001              0.06794  9.796691931034484  \n",
       "1   1.001  0.07760758620689655  9.796691931034484  \n",
       "2   1.001   0.0872751724137931  9.796691931034484  \n",
       "3   1.001  0.09694275862068966  9.796691931034484  \n",
       "4   1.001   0.1066103448275862  9.796691931034484  \n",
       "5   1.001  0.11627793103448275  9.796691931034484  \n",
       "6   1.001   0.1259455172413793  9.796691931034484  \n",
       "7   1.001  0.13561310344827587  9.796691931034484  \n",
       "8   1.001   0.1452806896551724  9.796691931034484  \n",
       "9   1.001  0.15494827586206894  9.796691931034484  \n",
       "10  1.001   0.1646158620689655  9.796691931034484  \n",
       "11  1.001  0.17428344827586206  9.796691931034484  \n",
       "12  1.001  0.18395103448275862  9.796691931034484  \n",
       "13  1.001  0.19361862068965516  9.796691931034484  \n",
       "14  1.001  0.20328620689655172  9.796691931034484  \n",
       "15  1.001  0.21295379310344825  9.796691931034484  \n",
       "16  1.001   0.2226213793103448  9.796691931034484  \n",
       "17  1.001  0.23228896551724137  9.796691931034484  \n",
       "18  1.001   0.2419565517241379  9.796691931034484  \n",
       "19  1.001  0.25162413793103444  9.796691931034484  \n",
       "20  1.001    0.261291724137931  9.796691931034484  \n",
       "21  1.001  0.27095931034482756  9.796691931034484  \n",
       "22  1.001   0.2806268965517241  9.796691931034484  \n",
       "23  1.001   0.2902944827586207  9.796691931034484  \n",
       "24  1.001  0.29996206896551725  9.796691931034484  \n",
       "25  1.001   0.3096296551724138  9.796691931034484  \n",
       "26  1.001   0.3192972413793103  9.796691931034484  \n",
       "27  1.001   0.3289648275862069  9.796691931034484  \n",
       "28  1.001  0.33863241379310344  9.796691931034484  \n",
       "29  1.001               0.3483  9.796691931034484  \n",
       "30  1.001              0.06794  9.863901862068966  \n",
       "31  1.001  0.07760758620689655  9.863901862068966  \n",
       "32  1.001   0.0872751724137931  9.863901862068966  \n",
       "33  1.001  0.09694275862068966  9.863901862068966  \n",
       "34  1.001   0.1066103448275862  9.863901862068966  \n",
       "35  1.001  0.11627793103448275  9.863901862068966  \n",
       "36  1.001   0.1259455172413793  9.863901862068966  \n",
       "37  1.001  0.13561310344827587  9.863901862068966  \n",
       "38  1.001   0.1452806896551724  9.863901862068966  \n",
       "39  1.001  0.15494827586206894  9.863901862068966  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_results[30:70,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors_temp = list(fit.extract(u'beta').items()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = np.array(posteriors_temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print posteriors.shape\n",
    "print posteriors[0,:,0] # row -- b0,b1,b2,b3,b4  --- betas\n",
    "print posteriors[0,:,:] # col -- w0,w1,w2,w3,w4  --- emission-line classification (WHAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks            = posteriors[:,0,0].size  # number of blocks of betas we have\n",
    "number_of_classes = n_class\n",
    "betas_size        = regression_data['K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mega-loop to extract and plot the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_dictionary = {}\n",
    "plots = {}\n",
    "colour='black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_class in range(number_of_classes):\n",
    "    for each_beta in range(betas_size):\n",
    "        print each_class, each_beta\n",
    "        betas_dictionary[\"beta{0}{1}\".format(each_class, each_beta)] = posteriors[:, each_beta, each_class]\n",
    "        print np.array(betas_dictionary.values()).size\n",
    "#         print np.array(betas_dictionary.values()).shape\n",
    "#         plot_position = len(betas_dictionary.keys())\n",
    "#         print each_beta, each_class, betas_dictionary.keys()[0]\n",
    "# #         for p in range(plot_position):\n",
    "#             plt.subplot(each_beta, each_class, p)\n",
    "#             sns.kdeplot(posteriors[:, each_beta, each_class], shade=True, c=colour)\n",
    "#             plt.xlabel(r\"$\\beta_{{0}{1}}$\".format(each_beta, each_class), fontsize=10)\n",
    "#             plt.tick_params('both', labelsize='10')\n",
    "           \n",
    "            \n",
    "#             plot = my_plots(x=posteriors[:, each_beta, each_class], row=each_beta, col=each_class, position=p)\n",
    "#             plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
