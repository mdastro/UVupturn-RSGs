{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to be called throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(parameter):\n",
    "    \"\"\"\n",
    "    :param parameter: the array with the parameters you wish to standardize\n",
    "    :return param_mean: mean of the input array\n",
    "    :return param_std : standard deviation of the input array\n",
    "    :return stdized_param: final standardized array\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    param_mean    = np.mean(parameter)\n",
    "    param_std     = np.std(parameter)\n",
    "    stdized_param = []                  # standardized parameter -- output\n",
    "    for i in range(parameter.size):\n",
    "        param_temp = (parameter[i] - param_mean)/param_std\n",
    "        stdized_param.append(param_temp)\n",
    "    stdized_param = np.array(stdized_param)\n",
    "    return (param_mean, param_std, stdized_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_standardize(stdized_par, mean, std):\n",
    "    \"\"\"\n",
    "    This function undoes what the former does!\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    recovered_par = []\n",
    "    for i in range(stdized_par.size):\n",
    "        param_temp = stdized_par[i]*std + mean\n",
    "        recovered_par.append(param_temp)\n",
    "    recovered_par = np.array(recovered_par)\n",
    "    return (recovered_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api   as sm\n",
    "import seaborn           as sns\n",
    "import pystan\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../../Catalogue/binom_reg_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the dataset\n",
    "redshifts = my_data['Z']\n",
    "index     = np.where(redshifts.values<=0.4)\n",
    "\n",
    "# parameters of interest\n",
    "logit_class = my_data['LOGIT_CLASS(1-UVUP;0-UVWEAK)'].values[index].astype(int)    # y axis: logit class: UVUP yes/no\n",
    "whan_class  = my_data['WHAN(0-NA;1-RP;2-wA;3-sA;4-SF)'].values[index].astype(int)  # My types of galaxies\n",
    "mass        = my_data['STELLAR_MASS'].values[index].astype(int)                    # 1st parameter\n",
    "redshift    = redshifts.values[index].astype(float)                                # 2nd parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original parameters\n",
    "mean_mass, std_mass, x2 = standardize(mass)\n",
    "x1      = redshift\n",
    "y       = logit_class\n",
    "classes = (whan_class+1).astype(int)        # Must sum +1 to avoid index issues with STAN\n",
    "n_obs   = x1.size\n",
    "n_class = np.unique(classes).size\n",
    "\n",
    "# new parameters - important for plotting!\n",
    "n_obs2 = 30\n",
    "x1_sim = np.linspace(x1.min(), x1.max(), n_obs2)\n",
    "x2_sim = np.linspace(x2.min(), x2.max(), n_obs2)\n",
    "\n",
    "# grid\n",
    "plot_x1, plot_x2 = np.meshgrid(x1_sim, x2_sim)  # THIS IS WHERE THE GRID IS DONE\n",
    "plot_x1 = plot_x1.reshape((n_obs2**2), 1)\n",
    "plot_x2 = plot_x2.reshape((n_obs2**2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.582215516074275 1.5690974667054223\n",
      "-0.5065590246844265\n",
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "print x2.min(), x2.max() # sanity check\n",
    "print np.median(x2)\n",
    "print plot_x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to be used in the regression\n",
    "regression_data      = {}                                                 # Dictionary, as stated in the pystan manual\n",
    "regression_data['Y'] = y\n",
    "regression_data['X'] = sm.add_constant(np.column_stack((x1, x1**2, x2, x2**2)))\n",
    "regression_data['K'] = regression_data['X'][0,:].size                     # Number of betas -- b0, b1, b2, b3, b4\n",
    "regression_data['W'] = classes\n",
    "regression_data['N'] = n_obs\n",
    "regression_data['C'] = n_class                                      # Number of different classes (partial pooling)\n",
    "\n",
    "# dataset to be used in the plot -- after meshgrid\n",
    "regression_data['X2'] = sm.add_constant(np.column_stack((plot_x1, plot_x1**2, plot_x2, plot_x2)))\n",
    "regression_data['N2'] = n_obs2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit: STAN code ----------------------------------------------------------------------------------------------------------\n",
    "stan_code = \"\"\"\n",
    "// DECLARATION OF VARIABLES -----------------------------------------------------------------------------------------------\n",
    "data{\n",
    "    int<lower=1> N;\n",
    "    int<lower=1> N2;\n",
    "    int<lower=1> K;\n",
    "    int<lower=1> C;\n",
    "    int W[N];\n",
    "    int<lower=0, upper=1> Y[N];\n",
    "    matrix[N, K] X;         // redshift and stellar mass \n",
    "    matrix[N2,K] X2;        // redshift and stellar mass -- after grid\n",
    "    }\n",
    "\n",
    "// DEFINING THE PRIOR(S) --------------------------------------------------------------------------------------------------\n",
    "parameters{\n",
    "    matrix[K,C] beta;       // 25 betas!\n",
    "//    real<lower=0> sigma;    // Shared hyperpriors\n",
    "//    real mu;                // Shared hyperpriors\n",
    "    }\n",
    "\n",
    "// MODEL: PROBABILITY, HYPERPRIORS, PRIORS, AND REGRESSION ----------------------------------------------------------------\n",
    "model {\n",
    "   vector[N] prob;\n",
    "    for (i in 1:N) {\n",
    "      prob[i] = beta[1,W[i]]*X[i,1] + beta[2,W[i]]*X[i,2] + beta[3,W[i]]*X[i,3] + beta[4,W[i]]*X[i,4] + \n",
    "      beta[5,W[i]]*X[i,5];\n",
    "      }\n",
    "\n",
    "//    sigma ~ gamma(0.001, 0.001);                           // shared hyperpriors\n",
    "//    mu ~ normal(0, 100);                                   // shared hyperpriors\n",
    "     \n",
    "//    for (i in 1:K) {\n",
    "//       for (j in 1:C) beta[i,j] ~ normal(mu, sigma);       // priors\n",
    "//        }\n",
    "\n",
    "    Y ~ bernoulli_logit(prob);                             // regression\n",
    "    }\n",
    "\n",
    "// DATA TO BE PLOTTED -----------------------------------------------------------------------------------------------------\n",
    "generated quantities{\n",
    "    vector[N2] prob01;\n",
    "    vector[N2] eta01;\n",
    "    vector[N2] prob02;\n",
    "    vector[N2] eta02;\n",
    "    vector[N2] prob03;\n",
    "    vector[N2] eta03;\n",
    "    vector[N2] prob04;\n",
    "    vector[N2] eta04;\n",
    "    vector[N2] prob05;\n",
    "    vector[N2] eta05;\n",
    "    \n",
    "    for(j in 1:N2){\n",
    "        eta01[j] = beta[1,1]*X2[j,1] + beta[2,1]*X2[j,2] + beta[3,1]*X2[j,3] + beta[4,1]*X2[j,4] + beta[5,1]*X2[j,5];\n",
    "        eta02[j] = beta[1,2]*X2[j,1] + beta[2,2]*X2[j,2] + beta[3,2]*X2[j,3] + beta[4,2]*X2[j,4] + beta[5,2]*X2[j,5];\n",
    "        eta03[j] = beta[1,3]*X2[j,1] + beta[2,3]*X2[j,2] + beta[3,3]*X2[j,3] + beta[4,3]*X2[j,4] + beta[5,3]*X2[j,5];\n",
    "        eta04[j] = beta[1,4]*X2[j,1] + beta[2,4]*X2[j,2] + beta[3,4]*X2[j,3] + beta[4,4]*X2[j,4] + beta[5,4]*X2[j,5];\n",
    "        eta05[j] = beta[1,5]*X2[j,1] + beta[2,5]*X2[j,2] + beta[3,5]*X2[j,3] + beta[4,5]*X2[j,4] + beta[5,5]*X2[j,5];\n",
    "        prob01[j] = inv_logit(eta01[j]);\n",
    "        prob02[j] = inv_logit(eta02[j]);\n",
    "        prob03[j] = inv_logit(eta03[j]);\n",
    "        prob04[j] = inv_logit(eta04[j]);\n",
    "        prob05[j] = inv_logit(eta05[j]);\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for running STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "chains     = 3                           # HMC chains\n",
    "warmup     = 1500                        # How many of the first iterations we'll ignore - burnin\n",
    "jobs       = -1                          # Run code in parallel -- see pystan documentation\n",
    "seed       = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pystan.stan??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = {}\n",
    "control['max_treedepth'] = 20\n",
    "control['adapt_delta'] = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "fit = pystan.stan(model_code=stan_code, data=regression_data, seed=seed, iter=iterations, chains=chains, \n",
    "                  warmup=warmup, n_jobs=jobs, control=control)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting fit properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot('beta')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pystan.stansummary(fit=fit, digits_summary=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_arr = np.array(summary.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = summary_arr[5:-6,]                                                    # removing header and footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting fit summary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_fit = summary_arr[4].split()\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_addendum = 'parameter'\n",
    "header_fit = [header_addendum] + header_fit\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cute_output = list(np.zeros(len(header_fit)))\n",
    "for i in range(new_output.size):\n",
    "    if len(new_output[i].split())!=11: # the length of the list must be 11, in which case we connect them directly\n",
    "#         print \"there is a problem!\"\n",
    "        print new_output[i]\n",
    "    else:\n",
    "        new_output_temp = np.array(new_output[i].split()).reshape(1,11)\n",
    "        cute_output     = np.vstack((cute_output, new_output_temp))\n",
    "cute_output = cute_output[1:,:]               # removing the zeroes in the beggining\n",
    "print cute_output[:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the fit results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the probabilities separately for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = {}\n",
    "probability['prob01'] = list(fit.extract(u'prob01').items()[0])[1]\n",
    "probability['prob02'] = list(fit.extract(u'prob02').items()[0])[1]\n",
    "probability['prob03'] = list(fit.extract(u'prob03').items()[0])[1]\n",
    "probability['prob04'] = list(fit.extract(u'prob04').items()[0])[1]\n",
    "probability['prob05'] = list(fit.extract(u'prob05').items()[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability['prob01'].shape  # 21000 (3 x 7000) interations for a grid 30x30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(n_class):\n",
    "    prob_temp = probability['prob0%d' % int(i+1)]\n",
    "    prob_tdf = pd.DataFrame(prob_temp)\n",
    "    prob_tdf.to_csv('../../LargeFilesResults/rm_sharedprior_prob0%d.csv' % int(i+1))\n",
    "end = time.time()\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Extracting and saving the fit summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_mass  = un_standardize(stdized_par=plot_x2, mean=mean_mass, std=std_mass)\n",
    "rp      = np.column_stack((plot_x1, recovered_mass))\n",
    "rp_cols = np.vstack((rp, rp, rp, rp, rp))       # for 5 whan classes we must stack these 5x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = cute_output[:,0].astype(str)\n",
    "pnew_idxs  = []\n",
    "for i in range(parameters.size):\n",
    "    if parameters[i][0:4]=='prob':\n",
    "        pnew_idxs.append(i)\n",
    "    else:\n",
    "        continue\n",
    "print cute_output[pnew_idxs,:].shape, rp_cols.shape\n",
    "model_results    = np.column_stack((cute_output[pnew_idxs,:], rp_cols))\n",
    "model_results_df = pd.DataFrame(model_results)\n",
    "model_results_df.columns = header_fit + ['Z'] + ['LOG_STELLAR_MASS']\n",
    "model_results_df.to_csv('../../LargeFilesResults/fit_summary_rm_sharedprior.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = list(fit.extract(u'beta').items()[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print posteriors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_row = posteriors[0,:,0].size  # rows are b0, b1, b2, b3, b4 -- posteriors given the regression\n",
    "matrix_col = posteriors[0,0,:].size  # cols are w0, w1, w2, w3, w4 -- WHAN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_dict = {}\n",
    "for line in range(matrix_row):\n",
    "    for col in range(matrix_col):\n",
    "        betas_dict[\"beta%d%d\" % (line, col)] = posteriors[:, line, col]\n",
    "betas_df = pd.DataFrame(betas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_df.to_csv('./../../LargeFilesResults/betas_rm_sharedprior.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the entire fit -- brace for impact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "fit_df = fit.to_dataframe()\n",
    "end = time.time()\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "fit_df.to_csv('../../LargeFilesResults/entirefit_rm_sharedpriors.csv', index=False)\n",
    "end = time.time()\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_idx = fit_df['chain_idx'].values.astype(int)\n",
    "chain     = fit_df['chain'].values.astype(int)\n",
    "beta11    = fit_df['beta[1,1]'].values.astype(float)\n",
    "beta12    = fit_df['beta[1,2]'].values.astype(float)\n",
    "chain1    = np.where(chain==1)\n",
    "chain2    = np.where(chain==2)\n",
    "chain3    = np.where(chain==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,3))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "sns.kdeplot(beta11[chain1], color='blue', alpha=0.6)\n",
    "sns.kdeplot(beta11[chain2], color='orange', alpha=0.6)\n",
    "sns.kdeplot(beta11[chain3], color='magenta', alpha=0.6)\n",
    "\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(chain_idx[chain1], beta11[chain1], color='blue', alpha=0.6)\n",
    "plt.plot(chain_idx[chain2], beta11[chain2], color='orange', alpha=0.6)\n",
    "plt.plot(chain_idx[chain3], beta11[chain3], color='magenta', alpha=0.6)\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "sns.kdeplot(beta12[chain1], color='blue', alpha=0.6)\n",
    "sns.kdeplot(beta12[chain2], color='orange', alpha=0.6)\n",
    "sns.kdeplot(beta12[chain3], color='magenta', alpha=0.6)\n",
    "\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.plot(chain_idx[chain1], beta12[chain1], color='blue', alpha=0.8)\n",
    "plt.plot(chain_idx[chain2], beta12[chain2], color='orange', alpha=0.6)\n",
    "plt.plot(chain_idx[chain3], beta12[chain3], color='magenta', alpha=0.4)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Results/example_beta_traceplot_rmsharedprior.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
