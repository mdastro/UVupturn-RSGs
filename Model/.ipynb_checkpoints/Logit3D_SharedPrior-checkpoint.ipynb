{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal functions to be called throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(parameter):\n",
    "    \"\"\"\n",
    "    :param parameter: the array with the parameters you wish to standardize\n",
    "    :return param_mean: mean of the input array\n",
    "    :return param_std : standard deviation of the input array\n",
    "    :return stdized_param: final standardized array\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    param_mean    = np.mean(parameter)\n",
    "    param_std     = np.std(parameter)\n",
    "    stdized_param = []                  # standardized parameter -- output\n",
    "    for i in range(parameter.size):\n",
    "        param_temp = (parameter[i] - param_mean)/param_std\n",
    "        stdized_param.append(param_temp)\n",
    "    stdized_param = np.array(stdized_param)\n",
    "    return (param_mean, param_std, stdized_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plots(x, row, col, position):\n",
    "    import numpy             as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn           as sns\n",
    "    \n",
    "#     plot_dict = {}\n",
    "#     plot_dict[\"plot{0}{1}\".format(row, col)] \n",
    "    fig = plt.subplot(row+1, col+1, position)\n",
    "    sns.kdeplot(x, shade=True, c='#e6550d')\n",
    "    plt.xlabel(r\"$\\beta_{%d%d}$\" % (row, col), fontsize=12)\n",
    "    plt.tick_params('both', labelsize='12')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return (fig)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api   as sm\n",
    "import seaborn           as sns\n",
    "import pystan\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('../../Catalogue/binom_reg_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'CATAID', u'BPT_CLASS', u'LOGIT_CLASS(1-UVUP;0-UVWEAK)',\n",
       "       u'STELLAR_MASS', u'UV_CLASS', u'WHAN(0-NA;1-RP;2-wA;3-sA;4-SF)',\n",
       "       u'WHAN_CLASS', u'Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the dataset\n",
    "redshifts = my_data['Z']\n",
    "index     = np.where(redshifts.values<=0.4)\n",
    "\n",
    "# parameters of interest\n",
    "logit_class = my_data['LOGIT_CLASS(1-UVUP;0-UVWEAK)'].values[index]    # y axis: logit class -- uv upturn yes or no\n",
    "whan_class  = my_data['WHAN(0-NA;1-RP;2-wA;3-sA;4-SF)'].values[index]  # My types of galaxies\n",
    "mass        = my_data['STELLAR_MASS'].values[index]                    # 1st parameter\n",
    "redshift    = redshifts.values[index]                                  # 2nd parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original parameters\n",
    "x1      = redshift\n",
    "x2      = standardize(mass)[2]\n",
    "y       = logit_class\n",
    "classes = (whan_class+1).astype(int)\n",
    "n_obs   = x1.size\n",
    "n_class = np.unique(classes).size\n",
    "\n",
    "# new parameters - important for plotting!\n",
    "n_obs2 = 30\n",
    "x1_sim = np.linspace(x1.min(), x1.max(), n_obs2)\n",
    "x2_sim = np.linspace(x2.min(), x2.max(), n_obs2)\n",
    "\n",
    "plot_x1, plot_x2 = np.meshgrid(x1_sim, x2_sim)  # THIS IS WHERE THE GRID IS DONE\n",
    "   \n",
    "plot_x1 = plot_x1.reshape((n_obs2**2), 1)\n",
    "plot_x2 = plot_x2.reshape((n_obs2**2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0048533107143856 2.6904846038511474\n",
      "0.018866401595684694\n",
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "print x2.min(), x2.max() # sanity check\n",
    "print np.median(x2)\n",
    "print plot_x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset to be used in the regression\n",
    "regression_data      = {}                                                 # Dictionary, as stated in the pystan manual\n",
    "regression_data['Y'] = y\n",
    "regression_data['X'] = sm.add_constant(np.column_stack((x1, x1**2, x2, x2**2)))\n",
    "regression_data['K'] = regression_data['X'][0,:].size                     # Number of betas -- b0, b1, b2, b3, b4\n",
    "regression_data['W'] = classes\n",
    "regression_data['N'] = n_obs\n",
    "regression_data['C'] = n_class                                      # Number of different classes (partial pooling)\n",
    "\n",
    "# dataset to be used in the plot -- after meshgrid\n",
    "regression_data['X2'] = sm.add_constant(np.column_stack((plot_x1, plot_x1**2, plot_x2, plot_x2)))\n",
    "regression_data['N2'] = n_obs2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 5)\n"
     ]
    }
   ],
   "source": [
    "print regression_data['X2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit: STAN code ----------------------------------------------------------------------------------------------------------\n",
    "stan_code = \"\"\"\n",
    "// DECLARATION OF VARIABLES -----------------------------------------------------------------------------------------------\n",
    "data{\n",
    "    int<lower=1> N;\n",
    "    int<lower=1> N2;\n",
    "    int<lower=1> K;\n",
    "    int<lower=1> C;\n",
    "    int W[N];\n",
    "    int<lower=0, upper=1> Y[N];\n",
    "    matrix[N, K] X;         // redshift and stellar mass \n",
    "    matrix[N2,K] X2;        // redshift and stellar mass -- after grid\n",
    "    }\n",
    "\n",
    "// DEFINING THE PRIOR(S) --------------------------------------------------------------------------------------------------\n",
    "parameters{\n",
    "    matrix[K,C] beta;       // 25 betas!\n",
    "    real<lower=0> sigma;    // Shared hyperpriors\n",
    "    real mu;                // Shared hyperpriors\n",
    "    }\n",
    "\n",
    "// MODEL: PROBABILITY, HYPERPRIORS, PRIORS, AND REGRESSION ----------------------------------------------------------------\n",
    "model {\n",
    "   vector[N] prob;\n",
    "    for (i in 1:N) {\n",
    "      prob[i] = beta[1,W[i]]*X[i,1] + beta[2,W[i]]*X[i,2] + beta[3,W[i]]*X[i,3] + beta[4,W[i]]*X[i,4] + \n",
    "      beta[5,W[i]]*X[i,5];\n",
    "      }\n",
    "\n",
    "    sigma ~ gamma(0.001, 0.001);                           // shared hyperpriors\n",
    "    mu ~ normal(0, 100);                                   // shared hyperpriors\n",
    "     \n",
    "    for (i in 1:K) {\n",
    "       for (j in 1:C) beta[i,j] ~ normal(mu, sigma);       // priors\n",
    "        }\n",
    "\n",
    "    Y ~ bernoulli_logit(prob);                             // regression\n",
    "    }\n",
    "\n",
    "// DATA TO BE PLOTTED -----------------------------------------------------------------------------------------------------\n",
    "generated quantities{\n",
    "    vector[N2] prob01;\n",
    "    vector[N2] eta01;\n",
    "    vector[N2] prob02;\n",
    "    vector[N2] eta02;\n",
    "    vector[N2] prob03;\n",
    "    vector[N2] eta03;\n",
    "    vector[N2] prob04;\n",
    "    vector[N2] eta04;\n",
    "    vector[N2] prob05;\n",
    "    vector[N2] eta05;\n",
    "    \n",
    "    for(j in 1:N2){\n",
    "        eta01[j] = beta[1,1]*X2[j,1] + beta[2,1]*X2[j,2] + beta[3,1]*X2[j,3] + beta[4,1]*X2[j,4] + beta[5,1]*X2[j,5];\n",
    "        eta02[j] = beta[1,2]*X2[j,1] + beta[2,2]*X2[j,2] + beta[3,2]*X2[j,3] + beta[4,2]*X2[j,4] + beta[5,2]*X2[j,5];\n",
    "        eta03[j] = beta[1,3]*X2[j,1] + beta[2,3]*X2[j,2] + beta[3,3]*X2[j,3] + beta[4,3]*X2[j,4] + beta[5,3]*X2[j,5];\n",
    "        eta04[j] = beta[1,4]*X2[j,1] + beta[2,4]*X2[j,2] + beta[3,4]*X2[j,3] + beta[4,4]*X2[j,4] + beta[5,4]*X2[j,5];\n",
    "        eta05[j] = beta[1,5]*X2[j,1] + beta[2,5]*X2[j,2] + beta[3,5]*X2[j,3] + beta[4,5]*X2[j,4] + beta[5,5]*X2[j,5];\n",
    "        prob01[j] = inv_logit(eta01[j]);\n",
    "        prob02[j] = inv_logit(eta02[j]);\n",
    "        prob03[j] = inv_logit(eta03[j]);\n",
    "        prob04[j] = inv_logit(eta04[j]);\n",
    "        prob05[j] = inv_logit(eta05[j]);\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for running STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations    = 8000\n",
    "chains        = 2\n",
    "warmup        = 2000    # How many of the first iterations we'll ignore - burnin\n",
    "jobs          = -1\n",
    "seed          = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control = {}\n",
    "# control['max_treedepth'] = 20\n",
    "# control['adapt_delta'] = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_902d543734551fafeca59854d8a03fd0 NOW.\n",
      "/home/mlldantas/anaconda3/envs/py2k7/lib/python2.7/site-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/tmpvsB80F/stanfit4anon_model_902d543734551fafeca59854d8a03fd0_7676263528157448635.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "WARNING:pystan:9 of 12000 iterations ended with a divergence (0%).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "fit = pystan.stan(model_code=stan_code, data=regression_data, seed=seed, iter=iterations, chains=chains, \n",
    "                  warmup=warmup, n_jobs=jobs)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "CPU process time: 8.77 [min]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"--------------------------------------------------\")\n",
    "print (\"CPU process time: %.2f [min]\" % float((end-start)/60))\n",
    "print (\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting fit properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print pystan.stansummary(fit=fit, digits_summary=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pystan.stansummary(fit=fit, digits_summary=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_arr = np.array(summary.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = summary_arr[5:-6,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'eta01[861]   0.031   0.008  0.562 -1.009 -0.355-6.01e-4  0.405  1.173   5128    1.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_output[1787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_output[1787] = 'eta01[861]   0.031   0.008  0.562 -1.009 -0.355-6.01e-4  0.405  1.173   5128    1.0' \n",
      "new_output[1788] = 'eta01[862]   0.031   0.008  0.563 -1.009 -0.356-1.12e-4  0.406  1.174   5115    1.0' \n",
      "new_output[1789] = 'eta01[863]    0.03   0.008  0.563  -1.01 -0.357-6.7e-4  0.406  1.174   5103    1.0' \n",
      "new_output[1790] = 'eta01[864]    0.03   0.008  0.563 -1.011 -0.358-9.47e-4  0.405  1.178   5090    1.0' \n",
      "new_output[1791] = 'eta01[865]   0.029   0.008  0.564 -1.011 -0.359-8.82e-4  0.405   1.18   5078    1.0' \n",
      "new_output[4634] = 'eta03[108]  -0.035   0.008  0.858 -1.835 -0.5369.64e-4  0.482  1.631  10455    1.0' \n",
      "new_output[4635] = 'eta03[109]  -0.035   0.008  0.858 -1.834 -0.5378.15e-4  0.482  1.633  10475    1.0' \n",
      "new_output[4636] = 'eta03[110]  -0.036   0.008  0.858 -1.835 -0.5389.73e-4  0.481  1.635  10495    1.0' \n",
      "new_output[4640] = 'eta03[114]  -0.038   0.008  0.858  -1.84 -0.5381.67e-4  0.479  1.634  10580    1.0' \n",
      "new_output[4641] = 'eta03[115]  -0.039   0.008  0.858 -1.845  -0.54-3.72e-4  0.478  1.631  10603    1.0' \n",
      "new_output[4656] = 'eta03[130]  -0.035   0.008  0.796  -1.71 -0.4996.57e-4  0.445   1.52  10281    1.0' \n",
      "new_output[4657] = 'eta03[131]  -0.036   0.008  0.796 -1.711   -0.52.42e-4  0.445  1.518  10298    1.0' \n",
      "new_output[4658] = 'eta03[132]  -0.036   0.008  0.796 -1.709   -0.5-6.13e-4  0.445  1.518  10315    1.0' \n",
      "new_output[6781] = 'eta04[455]  -0.149   0.002  0.245 -0.675 -0.288 -0.1344.77e-4  0.333  11886    1.0' \n",
      "new_output[6782] = 'eta04[456]   -0.15   0.002  0.246 -0.676 -0.289 -0.135-1.62e-5  0.334  11903    1.0' \n",
      "new_output[7208] = 'eta04[882]  -0.601   0.009  0.963 -2.613 -1.176 -0.567-1.87e-4  1.277  11285    1.0' \n",
      "new_output[7209] = 'eta04[883]  -0.602   0.009  0.964 -2.612 -1.177 -0.568-7.86e-4  1.275  11276    1.0' \n",
      "new_output[7210] = 'eta04[884]  -0.603   0.009  0.964 -2.611 -1.179 -0.568-8.13e-4  1.272  11266    1.0' \n",
      "new_output[7212] = 'eta04[886]  -0.604   0.009  0.965 -2.613 -1.181  -0.57-8.18e-4  1.271  11246    1.0' \n",
      "new_output[8640] = 'eta05[514]    -0.1   0.001  0.149 -0.411 -0.195 -0.0976.96e-4  0.189  12770    1.0' \n",
      "new_output[8641] = 'eta05[515]    -0.1   0.001  0.149 -0.412 -0.195 -0.0974.55e-4  0.188  12843    1.0' \n",
      "new_output[8643] = 'eta05[517]  -0.101   0.001  0.149 -0.413 -0.196 -0.0981.09e-4  0.187  12992    1.0' \n",
      "new_output[8644] = 'eta05[518]  -0.101   0.001  0.149 -0.412 -0.197 -0.099-1.48e-4  0.186  13068    1.0' \n",
      "new_output[8645] = 'eta05[519]  -0.102   0.001  0.149 -0.414 -0.197 -0.099-3.23e-4  0.186  13144    1.0' \n",
      "new_output[8646] = 'eta05[520]  -0.102   0.001   0.15 -0.414 -0.198   -0.1-7.72e-4  0.186  13222    1.0' \n",
      "new_output[8666] = 'eta05[540]  -0.112   0.001  0.167 -0.457 -0.217 -0.109-4.97e-4  0.212  14645    1.0' \n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# for i in range(new_output.size):\n",
    "#     row = np.array(new_output[i].split())\n",
    "#     if row.size ==11:\n",
    "#         continue\n",
    "#     else:\n",
    "#         print \"new_output[%d] = '%s' \" % (i, str(new_output[i]))\n",
    "#         count+=1\n",
    "# print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output[1787] = 'eta01[861]   0.031   0.008  0.562 -1.009 -0.355 -6.01e-4  0.405  1.173   5128    1.0' \n",
    "# new_output[1788] = 'eta01[862]   0.031   0.008  0.563 -1.009 -0.356 -1.12e-4  0.406  1.174   5115    1.0' \n",
    "# new_output[1789] = 'eta01[863]    0.03   0.008  0.563  -1.01 -0.357 -6.7e-4  0.406  1.174   5103    1.0' \n",
    "# new_output[1790] = 'eta01[864]    0.03   0.008  0.563 -1.011 -0.358 -9.47e-4  0.405  1.178   5090    1.0' \n",
    "# new_output[1791] = 'eta01[865]   0.029   0.008  0.564 -1.011 -0.359 -8.82e-4  0.405   1.18   5078    1.0' \n",
    "# new_output[4634] = 'eta03[108]  -0.035   0.008  0.858 -1.835 -0.536 9.64e-4  0.482  1.631  10455    1.0' \n",
    "# new_output[4635] = 'eta03[109]  -0.035   0.008  0.858 -1.834 -0.537 8.15e-4  0.482  1.633  10475    1.0' \n",
    "# new_output[4636] = 'eta03[110]  -0.036   0.008  0.858 -1.835 -0.538 9.73e-4  0.481  1.635  10495    1.0' \n",
    "# new_output[4640] = 'eta03[114]  -0.038   0.008  0.858  -1.84 -0.538 1.67e-4  0.479  1.634  10580    1.0' \n",
    "# new_output[4641] = 'eta03[115]  -0.039   0.008  0.858 -1.845  -0.54 -3.72e-4  0.478  1.631  10603    1.0' \n",
    "# new_output[4656] = 'eta03[130]  -0.035   0.008  0.796  -1.71 -0.499 6.57e-4  0.445   1.52  10281    1.0' \n",
    "# new_output[4657] = 'eta03[131]  -0.036   0.008  0.796 -1.711   -0.5 2.42e-4  0.445  1.518  10298    1.0' \n",
    "# new_output[4658] = 'eta03[132]  -0.036   0.008  0.796 -1.709   -0.5 -6.13e-4  0.445  1.518  10315    1.0' \n",
    "# new_output[6781] = 'eta04[455]  -0.149   0.002  0.245 -0.675 -0.288 -0.134 4.77e-4  0.333  11886    1.0' \n",
    "# new_output[6782] = 'eta04[456]   -0.15   0.002  0.246 -0.676 -0.289 -0.135 -1.62e-5  0.334  11903    1.0' \n",
    "# new_output[7208] = 'eta04[882]  -0.601   0.009  0.963 -2.613 -1.176 -0.567 -1.87e-4  1.277  11285    1.0' \n",
    "# new_output[7209] = 'eta04[883]  -0.602   0.009  0.964 -2.612 -1.177 -0.568 -7.86e-4  1.275  11276    1.0' \n",
    "# new_output[7210] = 'eta04[884]  -0.603   0.009  0.964 -2.611 -1.179 -0.568 -8.13e-4  1.272  11266    1.0' \n",
    "# new_output[7212] = 'eta04[886]  -0.604   0.009  0.965 -2.613 -1.181  -0.57 -8.18e-4  1.271  11246    1.0' \n",
    "# new_output[8640] = 'eta05[514]    -0.1   0.001  0.149 -0.411 -0.195 -0.097 6.96e-4  0.189  12770    1.0' \n",
    "# new_output[8641] = 'eta05[515]    -0.1   0.001  0.149 -0.412 -0.195 -0.097 4.55e-4  0.188  12843    1.0' \n",
    "# new_output[8643] = 'eta05[517]  -0.101   0.001  0.149 -0.413 -0.196 -0.098 1.09e-4  0.187  12992    1.0' \n",
    "# new_output[8644] = 'eta05[518]  -0.101   0.001  0.149 -0.412 -0.197 -0.099 -1.48e-4  0.186  13068    1.0' \n",
    "# new_output[8645] = 'eta05[519]  -0.102   0.001  0.149 -0.414 -0.197 -0.099 -3.23e-4  0.186  13144    1.0' \n",
    "# new_output[8646] = 'eta05[520]  -0.102   0.001   0.15 -0.414 -0.198   -0.1 -7.72e-4  0.186  13222    1.0' \n",
    "# new_output[8666] = 'eta05[540]  -0.112   0.001  0.167 -0.457 -0.217 -0.109 -4.97e-4  0.212  14645    1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(new_output.size):\n",
    "    row = np.array(new_output[i].split())\n",
    "    if row.size ==11:\n",
    "        continue\n",
    "    else:\n",
    "        print \"new_output[%d] = '%s' \" % (i, str(new_output[i]))\n",
    "        count+=1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'mean', u'se_mean', u'sd', u'2.5%', u'25%', u'50%', u'75%', u'97.5%', u'n_eff', u'Rhat']\n"
     ]
    }
   ],
   "source": [
    "header_fit = summary_arr[4].split()\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parameter', u'mean', u'se_mean', u'sd', u'2.5%', u'25%', u'50%', u'75%', u'97.5%', u'n_eff', u'Rhat']\n"
     ]
    }
   ],
   "source": [
    "header_addendum = 'parameter'\n",
    "header_fit = [header_addendum] + header_fit\n",
    "print header_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cute_output = list(np.zeros(len(header_fit)))\n",
    "for i in range(new_output.size):\n",
    "    if len(new_output[i].split())!=11: # the length of the list must be 11, in which case we connect them directly\n",
    "        print \"there is a problem!\"\n",
    "    else:\n",
    "        new_output_temp = np.array(new_output[i].split()).reshape(1,11)\n",
    "        cute_output     = np.vstack((cute_output, new_output_temp))\n",
    "cute_output = cute_output[1:,:]               # removing the zeroes in the beggining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and saving *ONLY* what really matters for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 11)\n",
      "(900, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = cute_output[:,0].astype(str)\n",
    "pnew_idxs  = []\n",
    "for i in range(parameters.size):\n",
    "    if parameters[i][0:4]=='prob':\n",
    "        pnew_idxs.append(i)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print cute_output[pnew_idxs,:].shape\n",
    "print plot_x1.shape\n",
    "\n",
    "# model_results    = np.column_stack((cute_output[pnew_idxs,:], x1_sim))\n",
    "# model_results_df.columns = header_fit + ['Z']\n",
    "model_results =\n",
    "model_results_df = pd.DataFrame(model_results)\n",
    "model_results_df.to_csv('./Results/fit_results_sharedprior.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'prob01[1]' u'prob01[2]' u'prob01[3]' ... u'prob05[898]' u'prob05[899]'\n",
      " u'prob05[900]']\n"
     ]
    }
   ],
   "source": [
    "print cute_output[pnew_idxs,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors_temp = list(fit.extract(u'beta').items()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = np.array(posteriors_temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 5, 5)\n",
      "[-0.33444698  0.02672725 -0.01634778  0.07920367 -0.17144219]\n",
      "[[-3.34446985e-01 -2.26543698e-01 -1.89228489e-01 -1.63251421e-01\n",
      "   3.76569607e-04]\n",
      " [ 2.67272508e-02  3.58492315e-02  1.68493309e-02 -5.13688809e-01\n",
      "   2.32375981e-01]\n",
      " [-1.63477759e-02  1.85788680e-01 -3.02080930e-01 -1.27353458e-01\n",
      "   1.76678414e-01]\n",
      " [ 7.92036677e-02  6.57353343e-02 -6.23788267e-02  8.68208981e-02\n",
      "   6.05670704e-02]\n",
      " [-1.71442189e-01 -8.80067036e-03  7.00294745e-02 -1.99786371e-01\n",
      "  -1.20829257e-01]]\n"
     ]
    }
   ],
   "source": [
    "print posteriors.shape\n",
    "print posteriors[0,:,0] # row -- b0,b1,b2,b3,b4  --- betas\n",
    "print posteriors[0,:,:] # col -- w0,w1,w2,w3,w4  --- emission-line classification (WHAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25537303, -0.16851336,  0.20990152,  0.16468466, -0.01015606],\n",
       "       [ 0.3766161 , -0.08229268,  0.53142079,  0.14922763,  0.15031719],\n",
       "       [-0.02091751,  0.15819203,  0.04783963,  0.10869276, -0.06914305],\n",
       "       [ 0.30031139,  0.47312253,  0.13617728,  0.19983463,  0.08732963],\n",
       "       [-0.09861625, -0.15494211, -0.07553024, -0.06665214,  0.02829974]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posteriors[11999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks            = posteriors[:,0,0].size  # number of blocks of betas we have\n",
    "number_of_classes = n_class\n",
    "betas_size        = regression_data['K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mega-loop to extract and plot the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_dictionary = {}\n",
    "plots = {}\n",
    "colour='black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "12000\n",
      "0 1\n",
      "24000\n",
      "0 2\n",
      "36000\n",
      "0 3\n",
      "48000\n",
      "0 4\n",
      "60000\n",
      "1 0\n",
      "72000\n",
      "1 1\n",
      "84000\n",
      "1 2\n",
      "96000\n",
      "1 3\n",
      "108000\n",
      "1 4\n",
      "120000\n",
      "2 0\n",
      "132000\n",
      "2 1\n",
      "144000\n",
      "2 2\n",
      "156000\n",
      "2 3\n",
      "168000\n",
      "2 4\n",
      "180000\n",
      "3 0\n",
      "192000\n",
      "3 1\n",
      "204000\n",
      "3 2\n",
      "216000\n",
      "3 3\n",
      "228000\n",
      "3 4\n",
      "240000\n",
      "4 0\n",
      "252000\n",
      "4 1\n",
      "264000\n",
      "4 2\n",
      "276000\n",
      "4 3\n",
      "288000\n",
      "4 4\n",
      "300000\n"
     ]
    }
   ],
   "source": [
    "for each_class in range(number_of_classes):\n",
    "    for each_beta in range(betas_size):\n",
    "        print each_class, each_beta\n",
    "        betas_dictionary[\"beta{0}{1}\".format(each_class, each_beta)] = posteriors[:, each_beta, each_class]\n",
    "        print np.array(betas_dictionary.values()).size\n",
    "#         print np.array(betas_dictionary.values()).shape\n",
    "#         plot_position = len(betas_dictionary.keys())\n",
    "#         print each_beta, each_class, betas_dictionary.keys()[0]\n",
    "# #         for p in range(plot_position):\n",
    "#             plt.subplot(each_beta, each_class, p)\n",
    "#             sns.kdeplot(posteriors[:, each_beta, each_class], shade=True, c=colour)\n",
    "#             plt.xlabel(r\"$\\beta_{{0}{1}}$\".format(each_beta, each_class), fontsize=10)\n",
    "#             plt.tick_params('both', labelsize='10')\n",
    "           \n",
    "            \n",
    "#             plot = my_plots(x=posteriors[:, each_beta, each_class], row=each_beta, col=each_class, position=p)\n",
    "#             plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
